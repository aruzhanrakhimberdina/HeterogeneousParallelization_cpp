# Контрольные вопросы к Assignment 3
## 1. Основные типы памяти в CUDA и их скорость

В архитектуре CUDA есть несколько основных типов памяти. Самая быстрая это регистры, которые находятся прямо внутри каждого потока и используются для временных переменных. Чуть медленнее работает разделяемая память, которая общая для всех потоков внутри одного блока и расположена на самом GPU. Глобальная память самая медленная, потому что она хранится вне вычислительных ядер и к ней обращаются все блоки. Также есть константная и текстурная память, которые предназначены для специальных случаев доступа к данным и могут быть быстрее глобальной при определенных шаблонах использования.

## 2. Когда разделяемая память ускоряет программу

Разделяемая память ускоряет программу, когда несколько потоков в одном блоке работают с одними и теми же данными. Вместо того чтобы каждый раз читать из медленной глобальной памяти, данные загружаются один раз в shared memory, а затем многократно используются потоками блока. Это особенно полезно в алгоритмах обработки массивов, матриц и при повторном доступе к одним и тем же элементам.

## 3. Влияние шаблона доступа к глобальной памяти

Шаблон доступа к памяти сильно влияет на производительность GPU. Если соседние потоки читают соседние элементы массива, доступ становится коалесцированным и выполняется эффективно. Если потоки читают данные хаотично или с большим шагом, доступ становится некоалесцированным, что приводит к большому количеству лишних обращений к памяти и снижает скорость работы программы.

## 4. Почему один и тот же алгоритм может работать по-разному

Один и тот же алгоритм может показывать разное время выполнения из-за способа обращения к памяти, размера блока потоков, количества операций и организации данных в памяти. Даже если логика алгоритма одинакова, плохая работа с памятью или неоптимальная конфигурация блоков может сильно замедлить выполнение на GPU.

## 5. Как размер блока потоков влияет на производительность

Размер блока потоков влияет на загрузку GPU и использование ресурсов. Если блок слишком маленький, многие ядра GPU будут простаивать. Если блок слишком большой, может не хватить регистров или разделяемой памяти, и производительность тоже снизится. Обычно хорошие значения это 128, 256 или 512 потоков на блок, но оптимальный размер зависит от конкретной задачи и архитектуры GPU.

## 6. Что такое варп и почему это важно

Варп это группа из 32 потоков, которые выполняются одновременно на GPU. Если потоки внутри варпа выполняют разные инструкции или обращаются к памяти по-разному, это вызывает расхождение и замедление работы. Поэтому важно писать код так, чтобы потоки в одном варпе работали максимально одинаково и обращались к памяти коалесцированно.

## 7. Что учитывать при выборе сетки и блоков

При выборе конфигурации нужно учитывать размер данных, доступную разделяемую память, количество регистров на поток и загрузку GPU. Важно, чтобы общее количество потоков покрывало все элементы массива, но при этом блоки не были слишком большими или слишком маленькими. Также важно учитывать архитектуру конкретного GPU и характер задачи.

## 8. Почему оптимизация начинается с памяти

Оптимизация CUDA обычно начинается с анализа работы с памятью, потому что именно память чаще всего является узким местом. Даже самый хороший алгоритм будет работать медленно, если он постоянно читает из глобальной памяти неэффективно. Поэтому сначала стараются улучшить доступ к памяти, а уже потом оптимизируют сам алгоритм вычислений.
