# Assignment 2

# Задача 1. Введение в гетерогенную параллелизацию

## Что такое гетерогенная параллелизация

Гетерогенная параллелизация - это подход к параллельным вычислениям, при котором используются разные типы вычислительных устройств одновременно, чаще всего CPU и GPU. Идея заключается в том, чтобы распределять задачи между ними в зависимости от того, какое устройство лучше подходит для конкретного типа вычислений: CPU - для сложной логики и управления, GPU - для массовых однотипных операций.

## Различия между параллельными вычислениями на CPU и GPU

CPU имеет небольшое количество мощных ядер (обычно от 4 до 16), которые хорошо подходят для последовательных вычислений, ветвлений и сложной логики. Он используется для управления программой, работы с вводом-выводом и обработки сложных сценариев.

GPU, наоборот, содержит тысячи простых ядер, предназначенных для выполнения одной и той же операции над большим количеством данных одновременно. Он особенно эффективен в задачах, связанных с линейной алгеброй, обработкой изображений, видео и обучением нейронных сетей.

Таким образом, CPU лучше подходит для управления и сложной логики, а GPU - для массовых параллельных вычислений.

## Преимущества гетерогенной параллелизации

Основное преимущество гетерогенной параллелизации - это более эффективное использование аппаратных ресурсов. Вместо того чтобы нагружать только одно устройство, программа использует сильные стороны каждого из них.

Это позволяет:
- значительно ускорять выполнение вычислений;
- обрабатывать большие объёмы данных за меньшее время;
- повышать общую производительность системы;
- гибко распределять задачи в зависимости от их типа.

## Примеры использования

Гетерогенная параллелизация широко используется в современных приложениях:

- в машинном обучении и нейронных сетях (обучение на GPU, подготовка данных на CPU);
- в компьютерной графике и играх (рендеринг на GPU, логика и физика на CPU);
- в научных и инженерных расчётах (моделирование климата, физические симуляции, биоинформатика);
- в обработке больших данных и изображений.

Во всех этих областях совместное использование CPU и GPU позволяет добиться высокой производительности и эффективности.

## Задача 2. Работа с массивами и OpenMP
task2.cpp
### Реализация
Программа:
- создаёт массив из 10 000 случайных чисел;
- находит минимальное и максимальное значения массива последовательно и параллельно;
- сравнивает время выполнения обеих реализаций.

  ---

## Задача 3. Параллельная сортировка с OpenMP
task3.cpp

### Реализация
Были реализованы:
- последовательная сортировка выбором;
- параллельная версия с использованием директив OpenMP;
- тестирование для массивов размером 1 000 и 10 000 элементов.

### Вывод  
Параллельная версия может быть быстрее для больших массивов, однако из-за синхронизации и накладных расходов выгода проявляется не всегда.

---

## Задача 4. Сортировка на GPU с использованием CUDA
task4.ipynb
### Реализация
Алгоритм состоит из следующих этапов:
- массив разбивается на подмассивы, каждый из которых сортируется отдельно на GPU;
- далее выполняются параллельные проходы слияния;
- измеряется время выполнения для массивов размером 10 000 и 100 000 элементов.

# Контрольные вопросы

## 1. Что понимается под гетерогенной параллелизацией?  
Гетерогенная параллелизация - это способ организации вычислений, при котором используются разные вычислительные устройства одновременно, например CPU и GPU. Каждое устройство выполняет ту часть работы, для которой оно лучше подходит. CPU обычно отвечает за управление программой и последовательные операции, а GPU используется для массовых параллельных вычислений над большими объёмами данных.

## 2. В чём принципиальные различия архитектур CPU и GPU?  
CPU имеет небольшое количество мощных универсальных ядер, которые хорошо справляются с задачами, требующими сложной логики, условий и ветвлений. GPU, наоборот, содержит тысячи простых ядер, оптимизированных для выполнения одинаковых операций над большим числом элементов одновременно. Поэтому CPU лучше подходит для управления программой, а GPU - для обработки данных в большом объёме.

## 3. Какие типы задач лучше подходят для выполнения на GPU, а какие — на CPU?  
Задачи, в которых одна и та же операция применяется к большому количеству данных (например, сортировка, обработка изображений, машинное обучение), лучше выполнять на GPU.  
Задачи, где много условий, переходов и последовательных шагов (например, логика программы, работа с файлами, взаимодействие с пользователем), лучше выполнять на CPU.

## 4. Почему не все алгоритмы эффективно распараллеливаются с использованием OpenMP?  
Некоторые алгоритмы имеют сильные зависимости между шагами, когда следующий шаг зависит от результата предыдущего. В таких случаях сложно разделить работу между потоками. Кроме того, создание потоков, синхронизация и обмен данными между ними тоже требуют времени, и для небольших задач эти накладные расходы могут превысить выигрыш от параллельного выполнения.

## 5. В чём заключается основная идея алгоритма сортировки слиянием?  
Алгоритм сортировки слиянием основан на принципе "разделяй и властвуй". Массив разбивается на несколько меньших частей, каждая часть сортируется отдельно, а затем отсортированные части объединяются в один общий отсортированный массив. Этот алгоритм хорошо подходит для параллелизации, так как части массива можно сортировать независимо.

## 6. Какие сложности возникают при реализации сортировки слиянием на GPU?  
Основные сложности связаны с тем, что операция слияния требует координации между потоками. Нужно правильно распределить работу, чтобы потоки не мешали друг другу и равномерно были загружены. Также необходимо учитывать ограничения памяти GPU и накладные расходы на копирование данных между CPU и GPU.

## 7. Как выбор размера блока и сетки влияет на производительность вычислений на GPU?  
Размер блока определяет, сколько потоков будет работать вместе, а размер сетки - сколько блоков будет запущено. Если блоки слишком маленькие, ресурсы GPU используются не полностью. Если слишком большие - может не хватить регистров или shared memory. Поэтому важно выбирать параметры так, чтобы максимально эффективно использовать вычислительные ресурсы GPU.

## 8. Почему гетерогенный подход может быть эффективнее использования только CPU или только GPU?  
Потому что разные типы задач требуют разных архитектур. CPU лучше подходит для управления и последовательных операций, а GPU - для массовых вычислений. Используя оба устройства вместе, можно распределить нагрузку оптимальным образом и получить более высокую производительность, чем при использовании только одного из них.
