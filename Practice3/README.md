# Практическая работа 3
### Контрольные вопросы 

 ---
 
## 1. В чем различие между последовательной и параллельной реализациями сортировки слиянием?
В последовательной реализации сортировки слиянием массив обрабатывается по шагам на одном процессоре. Массив рекурсивно делится на части, каждая часть сортируется, и затем части последовательно сливаются в один отсортированный массив. Все операции выполняются строго друг за другом.

В параллельной реализации разные части массива могут сортироваться одновременно в нескольких потоках. Например, каждая часть массива может обрабатываться отдельным блоком потоков на GPU. Слияние также может выполняться параллельно. Это позволяет существенно сократить общее время выполнения для больших массивов за счет одновременной обработки данных.

 ---

## 2. Как распределение потоков и блоков влияет на производительность на CUDA?
В CUDA потоки объединяются в блоки, а блоки распределяются между вычислительными модулями GPU. Если выбрать слишком мало потоков и блоков, часть вычислительных ресурсов GPU будет простаивать. Если выбрать слишком много потоков, может возникнуть нехватка памяти или избыточные накладные расходы на управление потоками.

Оптимальное распределение потоков и блоков позволяет равномерно загрузить GPU и обеспечить максимальный параллелизм. От этого напрямую зависит скорость выполнения программы.

--- 
## 3. Какие сложности возникают при реализации быстрой сортировки на GPU?

Быстрая сортировка имеет нерегулярную структуру. После выбора опорного элемента подмассивы могут сильно различаться по размеру. Из-за этого потоки выполняют разный объем работы, что приводит к дисбалансу нагрузки.

Кроме того, рекурсивная природа алгоритма плохо сочетается с моделью выполнения GPU, где предпочтительны простые и однородные вычисления. Это делает реализацию быстрой сортировки на GPU сложной и менее эффективной по сравнению с другими алгоритмами.
 
 ---
 
## 4. В каких случаях параллельная реализация сортировки на GPU может быть менее эффективной, чем на CPU?

При малых размерах массива время на передачу данных между CPU и GPU и запуск kernel может быть больше, чем время самой сортировки на CPU. В таких случаях использование GPU не дает выигрыша.

Также GPU менее эффективен для алгоритмов с большим количеством зависимостей между операциями или последовательных шагов, где параллелизм ограничен.

 ---
 
## 5. Почему важно правильно выбирать размер блоков и потоков в CUDA?

Размер блоков и потоков определяет, как задачи распределяются по вычислительным ресурсам GPU. Слишком маленькие блоки не используют GPU полностью. Слишком большие блоки могут привести к нехватке регистров или shared memory.

Правильный выбор параметров позволяет максимально эффективно использовать аппаратные ресурсы и уменьшить простои потоков.


 ---
## 6. Как использование разделяемой памяти может повлиять на производительность сортировки?

Разделяемая память значительно быстрее глобальной памяти GPU. Если данные временно сохраняются в shared memory, потоки могут обращаться к ним быстрее, чем при чтении из глобальной памяти.

Это особенно полезно для сортировок, где элементы многократно сравниваются и переставляются. Использование shared memory снижает задержки доступа к памяти и ускоряет работу алгоритма.

 ---
## 7. Что означает принцип "разделяй и властвуй" в контексте алгоритмов сортировки?

Принцип "разделяй и властвуй" означает разбиение большой задачи на несколько меньших подзадач, которые решаются независимо, а затем их результаты объединяются.

В сортировке слиянием массив делится на части, каждая часть сортируется отдельно, после чего они сливаются. В быстрой сортировке массив делится относительно опорного элемента на две части, которые сортируются отдельно. Такой подход упрощает задачу и позволяет эффективно применять параллельные вычисления.
