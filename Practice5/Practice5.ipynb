{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Практическое задание 5**"
      ],
      "metadata": {
        "id": "dBl7K8HB2D_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Часть 1"
      ],
      "metadata": {
        "id": "hfVu7g8D2XzL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuJYxYkQv9Gw",
        "outputId": "c0c10e42-a905-4714-a8a2-a99c0cfd6ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting stack_cuda.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile stack_cuda.cu\n",
        "\n",
        "// stack_cuda.cu\n",
        "// Часть 1: Параллельный стек на CUDA с атомарными операциями (push/pop)\n",
        "\n",
        "#include <iostream>                 // cout для вывода\n",
        "#include <vector>                   // vector для удобных массивов на CPU\n",
        "#include <cuda_runtime.h>           // CUDA runtime API (cudaMalloc/cudaMemcpy/events)\n",
        "\n",
        "using namespace std;                // чтобы не писать std:: каждый раз\n",
        "\n",
        "// Макрос: проверка ошибок CUDA-вызовов (если ошибка - печатаем и завершаем программу)\n",
        "#define CUDA_CHECK(x) do { \\\n",
        "  cudaError_t e = (x); \\\n",
        "  if (e != cudaSuccess) { \\\n",
        "    cout << \"CUDA error: \" << cudaGetErrorString(e) \\\n",
        "         << \" at \" << __FILE__ << \":\" << __LINE__ << \"\\n\"; \\\n",
        "    exit(1); \\\n",
        "  } \\\n",
        "} while(0)\n",
        "\n",
        "// Структура стека на GPU\n",
        "\n",
        "// Стек хранится в глобальной памяти GPU, а top меняется атомарно\n",
        "struct Stack {                                                      // объявляем структуру Stack\n",
        "    int *data;                                                      // указатель на массив данных в памяти GPU\n",
        "    int top;                                                        // индекс вершины стека (последний занятый элемент)\n",
        "    int capacity;                                                   // максимальный размер стека\n",
        "\n",
        "    __device__ void init(int *buffer, int size) {                   // device-функция инициализации стека на GPU\n",
        "        data = buffer;                                              // запоминаем адрес массива данных\n",
        "        top = -1;                                                   // стек пустой, поэтому top = -1\n",
        "        capacity = size;                                            // сохраняем емкость\n",
        "    }\n",
        "\n",
        "    __device__ bool push(int value) {                               // device-функция push: кладем значение в стек\n",
        "        int pos = atomicAdd(&top, 1) + 1;                           // атомарно увеличиваем top и получаем новую позицию\n",
        "        if (pos < capacity) {                                       // проверяем, что стек не переполнен\n",
        "            data[pos] = value;                                      // записываем значение в стек\n",
        "            return true;                                            // push успешен\n",
        "        } else {                                                    // если переполнение\n",
        "            atomicSub(&top, 1);                                     // откатываем top назад, чтобы не ломать состояние\n",
        "            return false;                                           // push не выполнен\n",
        "        }\n",
        "    }\n",
        "\n",
        "    __device__ bool pop(int *value) {                               // device-функция pop: достаем значение из стека\n",
        "        int pos = atomicSub(&top, 1);                               // атомарно уменьшаем top, pos - старое значение top\n",
        "        if (pos >= 0) {                                             // если было что доставать (pos был валидным индексом)\n",
        "            *value = data[pos];                                     // забираем значение из data[pos]\n",
        "            return true;                                            // pop успешен\n",
        "        } else {                                                    // если стек был пуст\n",
        "            atomicAdd(&top, 1);                                     // возвращаем top обратно (откат)\n",
        "            return false;                                           // pop не выполнен\n",
        "        }\n",
        "    }\n",
        "};\n",
        "\n",
        "// CUDA kernel: параллельные push/pop\n",
        "\n",
        "// Каждый поток: делает push своего id, потом часть потоков делает pop\n",
        "__global__ void testStackKernel(Stack *st, int *popOut, int N) {     // kernel, st - стек, popOut - массив результатов pop, N - число потоков\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;                // считаем глобальный id потока\n",
        "    if (tid >= N) return;                                           // защита, если потоков запустили больше чем N\n",
        "\n",
        "    bool okPush = st->push(tid);                                    // пытаемся положить tid в стек\n",
        "\n",
        "    __syncthreads();                                                // синхронизация внутри блока (чтобы чуть стабилизировать картину)\n",
        "\n",
        "    int v = -1;                                                     // сюда будем доставать значение\n",
        "    bool okPop = false;                                             // флаг успешности pop\n",
        "\n",
        "    if (okPush) {                                                   // pop имеет смысл только если push был успешен\n",
        "        okPop = st->pop(&v);                                        // пытаемся сделать pop\n",
        "    }\n",
        "\n",
        "    // Записываем результат: если pop успешен, пишем значение, иначе -1\n",
        "    popOut[tid] = (okPop ? v : -1);                                 // сохраняем результат для проверки на CPU\n",
        "}\n",
        "\n",
        "// Инициализация стека на GPU\n",
        "\n",
        "// kernel для init, потому что init - device-функция (ее нельзя вызвать напрямую с CPU)\n",
        "\n",
        "__global__ void initStackKernel(Stack *st, int *buffer, int cap) {   // kernel инициализации стека\n",
        "    if (threadIdx.x == 0 && blockIdx.x == 0) {                      // только один поток реально делает init\n",
        "        st->init(buffer, cap);                                      // вызываем init на устройстве\n",
        "    }\n",
        "}\n",
        "\n",
        "// main\n",
        "\n",
        "int main() {                                                        // старт программы\n",
        "    const int N = 1024;                                             // сколько потоков будем тестировать (push/pop)\n",
        "    const int CAP = 1024;                                           // емкость стека (фиксированная по заданию)\n",
        "\n",
        "    // Выделение памяти на GPU\n",
        "\n",
        "    Stack *dStack = nullptr;                                        // указатель на Stack в GPU памяти\n",
        "    int *dBuffer = nullptr;                                         // буфер данных стека в GPU памяти\n",
        "    int *dPopOut = nullptr;                                         // массив результатов pop в GPU памяти\n",
        "\n",
        "    CUDA_CHECK(cudaMalloc(&dStack, sizeof(Stack)));                 // выделяем память под структуру Stack\n",
        "    CUDA_CHECK(cudaMalloc(&dBuffer, CAP * sizeof(int)));            // выделяем память под данные стека\n",
        "    CUDA_CHECK(cudaMalloc(&dPopOut, N * sizeof(int)));              // выделяем память под массив результатов pop\n",
        "\n",
        "    // Инициализация стека\n",
        "\n",
        "    initStackKernel<<<1, 1>>>(dStack, dBuffer, CAP);                // запускаем kernel init (1 блок, 1 поток)\n",
        "    CUDA_CHECK(cudaGetLastError());                                 // проверяем запуск\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());                            // ждём завершения init\n",
        "\n",
        "    // Запуск тестового kernel\n",
        "\n",
        "    dim3 block(256);                                                // выбрали размер блока\n",
        "    dim3 grid((N + block.x - 1) / block.x);                         // считаем grid.x, чтобы покрыть N потоков\n",
        "\n",
        "    testStackKernel<<<grid, block>>>(dStack, dPopOut, N);           // запускаем kernel с push/pop\n",
        "    CUDA_CHECK(cudaGetLastError());                                 // проверяем запуск\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());                            // ждём завершения вычислений\n",
        "\n",
        "    // Копируем результаты pop на CPU\n",
        "\n",
        "    vector<int> hPop(N);                                            // массив на CPU для результатов pop\n",
        "    CUDA_CHECK(cudaMemcpy(hPop.data(), dPopOut, N * sizeof(int), cudaMemcpyDeviceToHost)); // копируем из GPU в CPU\n",
        "\n",
        "    // Проверка корректности\n",
        "\n",
        "    // Все значения должны быть из диапазона [0..N-1] или -1,\n",
        "    // и одинаковых значений (кроме -1) быть не должно, иначе стек отдал дубликаты\n",
        "\n",
        "    vector<int> seen(N, 0);                                         // seen[i]=1 если значение i уже встретили\n",
        "    int ok = 1;                                                     // флаг корректности\n",
        "    int poppedCount = 0;                                            // сколько успешных pop\n",
        "\n",
        "    for (int i = 0; i < N; ++i) {                                   // пробегаем по всем потокам\n",
        "        int v = hPop[i];                                            // берем то, что поток достал из стека\n",
        "        if (v == -1) continue;                                      // -1 значит pop не получился (например overflow/empty)\n",
        "        if (v < 0 || v >= N) {                                      // если достали что-то вне диапазона\n",
        "            ok = 0;                                                 // это ошибка\n",
        "            break;                                                  // дальше можно не проверять\n",
        "        }\n",
        "        if (seen[v]) {                                              // если значение уже встречали\n",
        "            ok = 0;                                                 // значит дубликат, это ошибка\n",
        "            break;                                                  // выходим\n",
        "        }\n",
        "        seen[v] = 1;                                                // отмечаем, что значение v уже было\n",
        "        poppedCount++;                                              // увеличиваем счетчик успешных pop\n",
        "    }\n",
        "\n",
        "    // Печать результата\n",
        "\n",
        "    cout << \"Parallel stack test\\n\";\n",
        "    cout << \"Threads N = \" << N << \"\\n\";                             // сколько потоков\n",
        "    cout << \"Stack capacity = \" << CAP << \"\\n\";                      // емкость стека\n",
        "    cout << \"Popped values (non -1) = \" << poppedCount << \"\\n\";      // сколько реально достали\n",
        "    cout << \"Correctness: \" << (ok ? \"OK\" : \"FAIL\") << \"\\n\";         // итог проверки\n",
        "\n",
        "    // Освобождение памяти\n",
        "\n",
        "    CUDA_CHECK(cudaFree(dStack));                                   // освобождаем Stack\n",
        "    CUDA_CHECK(cudaFree(dBuffer));                                  // освобождаем буфер данных\n",
        "    CUDA_CHECK(cudaFree(dPopOut));                                  // освобождаем результаты\n",
        "\n",
        "    return 0;                                                       // конец программы\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O3 -arch=sm_75 stack_cuda.cu -o stack_cuda\n",
        "!./stack_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7Lmbsb2xmKY",
        "outputId": "11f425c5-f2da-488c-b551-c310c5016c1b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parallel stack test\n",
            "Threads N = 1024\n",
            "Stack capacity = 1024\n",
            "Popped values (non -1) = 1024\n",
            "Correctness: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Вывод**\n",
        "В ходе выполнения работы была реализована параллельная структура данных стек на GPU с использованием атомарных операций для безопасного доступа к данным из множества потоков. Стек был инициализирован с фиксированной емкостью, после чего выполнялись параллельные операции push и pop в CUDA-ядре.\n",
        "\n",
        "Результаты эксперимента показали, что все 1024 потока смогли корректно записать и затем извлечь значения из стека. Количество успешно извлеченных элементов совпало с количеством выполненных операций push, что подтверждает отсутствие потерь данных и корректность работы алгоритма. Использование атомарных операций atomicAdd и atomicSub обеспечило синхронизацию потоков и предотвратило состояния гонки при одновременном доступе к переменной top.\n",
        "\n",
        "Таким образом, реализованный параллельный стек корректно функционирует в условиях многопоточного доступа и может быть использован как базовый механизм синхронизированного хранения данных на GPU."
      ],
      "metadata": {
        "id": "wj6JO85IywSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Часть 2"
      ],
      "metadata": {
        "id": "0fuPAr8D2j8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile queue_vs_stack.cu\n",
        "#include <iostream>              // cout\n",
        "#include <vector>                // vector на CPU\n",
        "#include <cuda_runtime.h>        // CUDA runtime + events\n",
        "#include <iomanip>               // setw, setprecision\n",
        "#include <cmath>                 // fabs\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// Проверка CUDA ошибок: если что-то пошло не так, сразу печатаем и выходим\n",
        "#define CUDA_CHECK(x) do { \\\n",
        "  cudaError_t e = (x); \\\n",
        "  if (e != cudaSuccess) { \\\n",
        "    cout << \"CUDA error: \" << cudaGetErrorString(e) << \" at \" << __FILE__ << \":\" << __LINE__ << \"\\n\"; \\\n",
        "    exit(1); \\\n",
        "  } \\\n",
        "} while(0)\n",
        "\n",
        "// Stack (из Part 1, чтобы сравнить)\n",
        "struct Stack {\n",
        "  int *data;        // буфер элементов в global memory\n",
        "  int top;          // индекс вершины\n",
        "  int capacity;     // емкость\n",
        "\n",
        "  __device__ void init(int *buffer, int size) {\n",
        "    data = buffer;          // привязываем буфер\n",
        "    top = -1;               // пустой стек\n",
        "    capacity = size;        // сохраняем емкость\n",
        "  }\n",
        "\n",
        "  __device__ bool push(int value) {\n",
        "    int pos = atomicAdd(&top, 1) + 1;   // резервируем позицию (top увеличили), pos = новый top\n",
        "    if (pos < capacity) {              // если не вышли за границы\n",
        "      data[pos] = value;               // кладем элемент\n",
        "      return true;                     // успех\n",
        "    }\n",
        "    atomicSub(&top, 1);                // откат, если переполнили\n",
        "    return false;                      // не удалось\n",
        "  }\n",
        "\n",
        "  __device__ bool pop(int *value) {\n",
        "    int pos = atomicSub(&top, 1);      // забираем текущий top и уменьшаем\n",
        "    if (pos >= 0) {                    // если стек был не пустой\n",
        "      *value = data[pos];              // читаем значение\n",
        "      return true;                     // успех\n",
        "    }\n",
        "    atomicAdd(&top, 1);                // откат, если стек был пустой\n",
        "    return false;                      // не удалось\n",
        "  }\n",
        "};\n",
        "\n",
        "// Queue (Part 2)\n",
        "struct Queue {\n",
        "  int *data;        // буфер элементов\n",
        "  int head;         // откуда читаем\n",
        "  int tail;         // куда пишем\n",
        "  int capacity;     // емкость\n",
        "\n",
        "  __device__ void init(int *buffer, int size) {\n",
        "    data = buffer;          // привязка буфера\n",
        "    head = 0;               // начало очереди\n",
        "    tail = 0;               // конец очереди\n",
        "    capacity = size;        // емкость\n",
        "  }\n",
        "\n",
        "  __device__ bool enqueue(int value) {\n",
        "    int pos = atomicAdd(&tail, 1);     // резервируем позицию в конце\n",
        "    if (pos < capacity) {              // если не вышли за емкость\n",
        "      data[pos] = value;               // пишем значение\n",
        "      return true;                     // успех\n",
        "    }\n",
        "\n",
        "    return false;                      // не удалось\n",
        "  }\n",
        "\n",
        "  __device__ bool dequeue(int *value) {\n",
        "    int pos = atomicAdd(&head, 1);     // резервируем позицию для чтения\n",
        "    // Сравниваем с tail (сколько реально добавили)\n",
        "    // Здесь для корректности мы будем вызывать dequeue только после того, как все enqueue закончились в блоке\n",
        "    if (pos < tail) {                  // если в очереди есть элементы\n",
        "      *value = data[pos];              // читаем элемент\n",
        "      return true;                     // успех\n",
        "    }\n",
        "    return false;                      // пусто\n",
        "  }\n",
        "};\n",
        "\n",
        "// Kernels\n",
        "\n",
        "// Инициализация стека (один поток)\n",
        "\n",
        "__global__ void initStackKernel(Stack *S, int *buf, int cap) {\n",
        "  if (threadIdx.x == 0) S->init(buf, cap);\n",
        "}\n",
        "\n",
        "// Инициализация очереди (один поток)\n",
        "\n",
        "__global__ void initQueueKernel(Queue *Q, int *buf, int cap) {\n",
        "  if (threadIdx.x == 0) Q->init(buf, cap);\n",
        "}\n",
        "\n",
        "// Тест стека: все потоки делают push, потом pop (внутри одного блока)\n",
        "\n",
        "__global__ void stackTestKernel(Stack *S, int *out, int nThreads) {\n",
        "  int tid = threadIdx.x;\n",
        "\n",
        "  if (tid < nThreads) {\n",
        "    S->push(tid);                 // каждый поток кладет свой tid\n",
        "  }\n",
        "  __syncthreads();                // ждём пока все push закончатся\n",
        "\n",
        "  int val = -1;                   // если pop не удастся, останется -1\n",
        "  if (tid < nThreads) {\n",
        "    S->pop(&val);                 // каждый поток пытается вытащить\n",
        "    out[tid] = val;               // записываем результат\n",
        "  }\n",
        "}\n",
        "\n",
        "// Тест очереди: сначала enqueue от всех потоков, потом dequeue от всех потоков (внутри одного блока)\n",
        "\n",
        "__global__ void queueTestKernel(Queue *Q, int *out, int nThreads) {\n",
        "  int tid = threadIdx.x;\n",
        "\n",
        "  if (tid < nThreads) {\n",
        "    Q->enqueue(tid);              // каждый поток добавляет свой tid в хвост\n",
        "  }\n",
        "  __syncthreads();                // после этого tail уже “зафиксирован” для блока\n",
        "\n",
        "  int val = -1;                   // если dequeue не удастся, будет -1\n",
        "  if (tid < nThreads) {\n",
        "    Q->dequeue(&val);             // каждый поток забирает один элемент\n",
        "    out[tid] = val;               // пишем что забрали\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "// Замеряем только kernel time через CUDA events\n",
        "\n",
        "template <typename Launch>\n",
        "float timeKernel(Launch launch) {\n",
        "  cudaEvent_t e1, e2;\n",
        "  CUDA_CHECK(cudaEventCreate(&e1));\n",
        "  CUDA_CHECK(cudaEventCreate(&e2));\n",
        "\n",
        "  CUDA_CHECK(cudaEventRecord(e1));\n",
        "  launch();\n",
        "  CUDA_CHECK(cudaEventRecord(e2));\n",
        "  CUDA_CHECK(cudaEventSynchronize(e2));\n",
        "\n",
        "  float ms = 0.0f;\n",
        "  CUDA_CHECK(cudaEventElapsedTime(&ms, e1, e2));\n",
        "\n",
        "  CUDA_CHECK(cudaEventDestroy(e1));\n",
        "  CUDA_CHECK(cudaEventDestroy(e2));\n",
        "  return ms;\n",
        "}\n",
        "\n",
        "\n",
        "// Проверка очереди: должны получить ровно nThreads значений из диапазона [0..nThreads-1], без повторов\n",
        "\n",
        "bool checkQueueResult(const vector<int>& out, int nThreads) {\n",
        "  vector<int> seen(nThreads, 0);\n",
        "\n",
        "  for (int i = 0; i < nThreads; i++) {\n",
        "    int v = out[i];\n",
        "    if (v < 0 || v >= nThreads) return false;  // вылезли за диапазон или -1\n",
        "    if (seen[v]) return false;                 // повтор\n",
        "    seen[v] = 1;\n",
        "  }\n",
        "  return true;\n",
        "}\n",
        "\n",
        "// Проверка стека: тоже должны получить nThreads валидных значений без -1\n",
        "// (порядок для стека будет LIFO, но нам важно что все элементы реально достались)\n",
        "\n",
        "bool checkStackResult(const vector<int>& out, int nThreads) {\n",
        "  vector<int> seen(nThreads, 0);\n",
        "\n",
        "  for (int i = 0; i < nThreads; i++) {\n",
        "    int v = out[i];\n",
        "    if (v < 0 || v >= nThreads) return false;\n",
        "    if (seen[v]) return false;\n",
        "    seen[v] = 1;\n",
        "  }\n",
        "  return true;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  const int NTHREADS = 1024;                 // как у нас в стеке, максимум для одного блока\n",
        "  const int CAPACITY = 1024;                // емкость очереди/стека\n",
        "\n",
        "  // Выделяем память на GPU под буферы данных\n",
        "  int *dBufStack = nullptr, *dBufQueue = nullptr;\n",
        "  int *dOutStack = nullptr, *dOutQueue = nullptr;\n",
        "\n",
        "  CUDA_CHECK(cudaMalloc(&dBufStack, CAPACITY * sizeof(int)));\n",
        "  CUDA_CHECK(cudaMalloc(&dBufQueue, CAPACITY * sizeof(int)));\n",
        "  CUDA_CHECK(cudaMalloc(&dOutStack, NTHREADS * sizeof(int)));\n",
        "  CUDA_CHECK(cudaMalloc(&dOutQueue, NTHREADS * sizeof(int)));\n",
        "\n",
        "  // Выделяем память на GPU под сами структуры Stack и Queue\n",
        "  Stack *dStack = nullptr;\n",
        "  Queue *dQueue = nullptr;\n",
        "  CUDA_CHECK(cudaMalloc(&dStack, sizeof(Stack)));\n",
        "  CUDA_CHECK(cudaMalloc(&dQueue, sizeof(Queue)));\n",
        "\n",
        "  // Инициализируем структуры на GPU\n",
        "  initStackKernel<<<1, 1>>>(dStack, dBufStack, CAPACITY);\n",
        "  initQueueKernel<<<1, 1>>>(dQueue, dBufQueue, CAPACITY);\n",
        "  CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "  // Настройки запуска: один блок и NTHREADS потоков\n",
        "  dim3 block(NTHREADS);\n",
        "  dim3 grid(1);\n",
        "\n",
        "  // Прогрев, чтобы первый запуск не портил измерение\n",
        "  stackTestKernel<<<grid, block>>>(dStack, dOutStack, NTHREADS);\n",
        "  queueTestKernel<<<grid, block>>>(dQueue, dOutQueue, NTHREADS);\n",
        "  CUDA_CHECK(cudaDeviceSynchronize());\n",
        "\n",
        "  // Замер времени стека\n",
        "  float tStack = timeKernel([&] {\n",
        "    initStackKernel<<<1, 1>>>(dStack, dBufStack, CAPACITY);          // заново обнуляем top\n",
        "    stackTestKernel<<<grid, block>>>(dStack, dOutStack, NTHREADS);\n",
        "  });\n",
        "\n",
        "  // Замер времени очереди\n",
        "  float tQueue = timeKernel([&] {\n",
        "    initQueueKernel<<<1, 1>>>(dQueue, dBufQueue, CAPACITY);          // заново обнуляем head/tail\n",
        "    queueTestKernel<<<grid, block>>>(dQueue, dOutQueue, NTHREADS);\n",
        "  });\n",
        "\n",
        "  // Скачиваем результаты на CPU для проверки корректности\n",
        "  vector<int> hStack(NTHREADS), hQueue(NTHREADS);\n",
        "  CUDA_CHECK(cudaMemcpy(hStack.data(), dOutStack, NTHREADS * sizeof(int), cudaMemcpyDeviceToHost));\n",
        "  CUDA_CHECK(cudaMemcpy(hQueue.data(), dOutQueue, NTHREADS * sizeof(int), cudaMemcpyDeviceToHost));\n",
        "\n",
        "  bool okStack = checkStackResult(hStack, NTHREADS);\n",
        "  bool okQueue = checkQueueResult(hQueue, NTHREADS);\n",
        "\n",
        "  // Красивый вывод\n",
        "  cout << \"Parallel data structures test (CUDA)\\n\";\n",
        "  cout << \"Threads N = \" << NTHREADS << \"\\n\";\n",
        "  cout << \"Capacity  = \" << CAPACITY << \"\\n\\n\";\n",
        "\n",
        "  cout << left << setw(12) << \"Structure\"\n",
        "       << setw(18) << \"Kernel time (ms)\"\n",
        "       << setw(14) << \"Correctness\"\n",
        "       << \"\\n\";\n",
        "\n",
        "  cout << left << setw(12) << \"Stack\"\n",
        "       << setw(18) << fixed << setprecision(6) << tStack\n",
        "       << setw(14) << (okStack ? \"OK\" : \"FAIL\")\n",
        "       << \"\\n\";\n",
        "\n",
        "  cout << left << setw(12) << \"Queue\"\n",
        "       << setw(18) << fixed << setprecision(6) << tQueue\n",
        "       << setw(14) << (okQueue ? \"OK\" : \"FAIL\")\n",
        "       << \"\\n\";\n",
        "\n",
        "  // Освобождение GPU памяти\n",
        "  CUDA_CHECK(cudaFree(dBufStack));\n",
        "  CUDA_CHECK(cudaFree(dBufQueue));\n",
        "  CUDA_CHECK(cudaFree(dOutStack));\n",
        "  CUDA_CHECK(cudaFree(dOutQueue));\n",
        "  CUDA_CHECK(cudaFree(dStack));\n",
        "  CUDA_CHECK(cudaFree(dQueue));\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owZ-1zODy775",
        "outputId": "8c080114-209b-4f13-8ca2-ab6b3ed290d7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting queue_vs_stack.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O3 -arch=sm_75 queue_vs_stack.cu -o queue_vs_stack\n",
        "!./queue_vs_stack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPkN2gcW0y0o",
        "outputId": "2045b0d0-a342-4e05-f1f9-e5fdf47f2672"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parallel data structures test (CUDA)\n",
            "Threads N = 1024\n",
            "Capacity  = 1024\n",
            "\n",
            "Structure   Kernel time (ms)  Correctness   \n",
            "Stack       0.013824          OK            \n",
            "Queue       0.010368          OK            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Вывод**\n",
        "В ходе выполнения задания была реализована параллельная структура данных стек и очередь на CUDA с использованием атомарных операций для безопасного доступа из нескольких потоков. Тестирование проводилось для 1024 потоков при фиксированной ёмкости 1024 элементов, при этом измерялось только время выполнения ядра без учёта передачи данных между CPU и GPU.\n",
        "\n",
        "Обе структуры корректно обработали все операции push/pop и enqueue/dequeue, что подтверждается результатом проверки корректности. По времени выполнения очередь показала более высокую производительность (0.010368 мс) по сравнению со стеком (0.013824 мс).\n",
        "\n",
        "Разница в производительности связана с особенностями работы атомарных операций. В стеке все потоки конкурируют за одну переменную top, что увеличивает задержки при параллельном доступе. В очереди операции распределены между двумя переменными head и tail, что снижает уровень конфликтов между потоками и делает работу более эффективной.\n",
        "\n",
        "Таким образом, при высокой степени параллелизма очередь может работать быстрее, чем стек, благодаря меньшей нагрузке на атомарные операции."
      ],
      "metadata": {
        "id": "88wKko-017vq"
      }
    }
  ]
}