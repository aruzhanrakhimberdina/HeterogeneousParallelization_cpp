{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Практическое задание 4**"
      ],
      "metadata": {
        "id": "UYI0CaGinRvI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49uYpIxk9soF",
        "outputId": "23a98ce2-83a9-4b8f-cd79-8457453b9a90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting practice4.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile practice4.cu\n",
        "#include <iostream>   // для вывода в консоль (cout)\n",
        "#include <vector>     // для работы с массивами на CPU\n",
        "#include <random>     // для генерации случайных чисел\n",
        "#include <cuda_runtime.h> // CUDA API (kernel-и, память, события)\n",
        "#include <iomanip>    // для красивого табличного вывода\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// Макрос: проверка ошибок CUDA-вызовов (если ошибка - печатаем и завершаем программу)\n",
        "#define CUDA_CHECK(x) do { \\\n",
        "  cudaError_t e = (x); \\\n",
        "  if (e != cudaSuccess) { \\\n",
        "    cout << \"CUDA error: \" << cudaGetErrorString(e) \\\n",
        "         << \" at \" << __FILE__ << \":\" << __LINE__ << \"\\n\"; \\\n",
        "    exit(1); \\\n",
        "  } \\\n",
        "} while(0)\n",
        "\n",
        "// Базовые параметры программы\n",
        "static const int BLOCK = 256;  // стандартный размер блока потоков для kernel-ов\n",
        "static const int CHUNK = 256;  // размер маленьких подмассивов (чанков) для пузырьковой сортировки\n",
        "\n",
        "\n",
        "// Универсальная функция-таймер на CUDA events\n",
        "// Она принимает \"launch\" - лямбду, внутри которой мы запускаем нужные kernel-ы\n",
        "// Мы измеряем только время выполнения kernel, без копирования памяти\n",
        "\n",
        "template <typename Launch>\n",
        "float timeKernel(Launch launch) {\n",
        "    cudaEvent_t evStart, evStop;\n",
        "\n",
        "    // Создаём события начала и конца измерения\n",
        "    CUDA_CHECK(cudaEventCreate(&evStart));\n",
        "    CUDA_CHECK(cudaEventCreate(&evStop));\n",
        "\n",
        "    // Записываем время начала\n",
        "    CUDA_CHECK(cudaEventRecord(evStart));\n",
        "\n",
        "    // Запускаем переданные kernel-и\n",
        "    launch();\n",
        "\n",
        "    // Записываем время окончания\n",
        "    CUDA_CHECK(cudaEventRecord(evStop));\n",
        "\n",
        "    // Ждём, пока всё реально выполнится на GPU\n",
        "    CUDA_CHECK(cudaEventSynchronize(evStop));\n",
        "\n",
        "    // Считаем разницу во времени\n",
        "    float ms = 0.0f;\n",
        "    CUDA_CHECK(cudaEventElapsedTime(&ms, evStart, evStop));\n",
        "\n",
        "    // Освобождаем события\n",
        "    CUDA_CHECK(cudaEventDestroy(evStart));\n",
        "    CUDA_CHECK(cudaEventDestroy(evStop));\n",
        "\n",
        "    return ms; // возвращаем время выполнения в миллисекундах\n",
        "}\n",
        "\n",
        "// Task 2: Reduction\n",
        "\n",
        "// Редукция только через глобальную память\n",
        "// Каждый поток берёт свой элемент и сразу делает atomicAdd в одну общую сумму\n",
        "// Просто, но медленно, потому что все потоки \"дерутся\" за одну ячейку памяти\n",
        "\n",
        "__global__ void reduce_global_only(const float* in, float* sum, int N) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x; // глобальный индекс элемента\n",
        "    if (i < N) {\n",
        "        atomicAdd(sum, in[i]); // добавляем элемент в общую сумму (атомарно)\n",
        "    }\n",
        "}\n",
        "\n",
        "// Редукция с использованием глобальной + разделяемой памяти\n",
        "// Каждый блок сначала суммирует свои элементы внутри shared memory\n",
        "// Потом только один поток от блока делает atomicAdd в глобальную сумму\n",
        "// Это сильно уменьшает число атомарных операций\n",
        "\n",
        "__global__ void reduce_shared(const float* in, float* sum, int N) {\n",
        "    __shared__ float s[BLOCK]; // shared memory на уровне блока\n",
        "\n",
        "    int tid = threadIdx.x; // номер потока внутри блока\n",
        "    int i   = blockIdx.x * blockDim.x + tid; // глобальный индекс элемента\n",
        "\n",
        "    // Загружаем данные в shared memory (или 0, если вышли за границы)\n",
        "    s[tid] = (i < N) ? in[i] : 0.0f;\n",
        "    __syncthreads(); // ждём, пока все потоки загрузят данные\n",
        "\n",
        "    // Классическая параллельная редукция в shared memory\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        if (tid < stride) {\n",
        "            s[tid] += s[tid + stride]; // складываем пары элементов\n",
        "        }\n",
        "        __syncthreads(); // синхронизация после каждого шага\n",
        "    }\n",
        "\n",
        "    // Только поток 0 записывает результат блока в глобальную сумму\n",
        "    if (tid == 0) {\n",
        "        atomicAdd(sum, s[0]);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Task 3: Sort pipeline\n",
        "\n",
        "// Пузырьковая сортировка маленьких чанков\n",
        "// Каждый блок сортирует свой кусок массива размером CHUNK\n",
        "\n",
        "__global__ void bubble_chunks(float* a, int N) {\n",
        "\n",
        "    // Shared memory для хранения одного чанка\n",
        "    __shared__ float s[CHUNK];\n",
        "\n",
        "    // Начало текущего чанка в глобальном массиве\n",
        "    int base = blockIdx.x * CHUNK;\n",
        "\n",
        "    // Локальный индекс потока внутри блока\n",
        "    int tid = threadIdx.x;\n",
        "\n",
        "    // Глобальный индекс элемента\n",
        "    int idx = base + tid;\n",
        "\n",
        "    // Загружаем данные в shared memory\n",
        "    // Если вышли за границы, кладём очень большое число (padding)\n",
        "    s[tid] = (idx < N) ? a[idx] : 1e30f;\n",
        "\n",
        "    // Синхронизация потоков блока\n",
        "    __syncthreads();\n",
        "\n",
        "    // Пузырьковую сортировку выполняет только поток 0\n",
        "    if (tid == 0) {\n",
        "        for (int i = 0; i < CHUNK - 1; i++) {\n",
        "            for (int j = 0; j < CHUNK - 1 - i; j++) {\n",
        "                if (s[j] > s[j + 1]) {\n",
        "                    float t = s[j];\n",
        "                    s[j] = s[j + 1];\n",
        "                    s[j + 1] = t;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Ждём завершения сортировки\n",
        "    __syncthreads();\n",
        "\n",
        "    // Записываем отсортированный чанк обратно в глобальную память\n",
        "    if (idx < N) {\n",
        "        a[idx] = s[tid];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Вспомогательная функция: бинарный поиск (lower_bound) внутри shared memory\n",
        "// Нужна для корректного слияния двух отсортированных сегментов\n",
        "__device__ __forceinline__ int lowerBoundShared(const float* R, int n, float x) {\n",
        "    int lo = 0, hi = n;\n",
        "    while (lo < hi) {\n",
        "        int mid = (lo + hi) >> 1;\n",
        "        if (R[mid] < x) lo = mid + 1;\n",
        "        else hi = mid;\n",
        "    }\n",
        "    return lo;\n",
        "}\n",
        "\n",
        "// Kernel для слияния двух отсортированных сегментов длины width\n",
        "// Мы загружаем оба сегмента в shared memory,\n",
        "// а потом параллельно формируем отсортированный результат\n",
        "\n",
        "__global__ void merge_pass(const float* in, float* out, int N, int width) {\n",
        "    int base = blockIdx.x * (2 * width); // начало пары сегментов\n",
        "    int tid  = threadIdx.x;              // номер потока в блоке\n",
        "\n",
        "    int m = max(0, min(width, N - base));          // реальный размер левого сегмента\n",
        "    int n = max(0, min(width, N - (base + width))); // реальный размер правого сегмента\n",
        "    int outLen = m + n; // длина результата слияния\n",
        "\n",
        "    extern __shared__ float sh[];\n",
        "    float* L = sh;           // левый сегмент в shared memory\n",
        "    float* R = sh + width;   // правый сегмент в shared memory\n",
        "\n",
        "    // Загружаем L и R в shared memory\n",
        "    for (int i = tid; i < width; i += blockDim.x) {\n",
        "        L[i] = (i < m) ? in[base + i] : 1e30f;\n",
        "        R[i] = (i < n) ? in[base + width + i] : 1e30f;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    // Каждый поток пишет несколько элементов результата\n",
        "for (int k = tid; k < outLen; k += blockDim.x) {\n",
        "    // Цикл распределяет работу между потоками блока:\n",
        "    // каждый поток обрабатывает позиции k, k+blockDim.x, k+2*blockDim.x и т.д.\n",
        "\n",
        "    int iGuess = min(k, m);\n",
        "    // Берём начальное предположение, сколько элементов взять из левого массива L\n",
        "\n",
        "    float a = (iGuess < m) ? L[iGuess] : 1e30f;\n",
        "    // Если iGuess внутри левого массива, берем L[iGuess],\n",
        "    // иначе ставим очень большое число как padding\n",
        "\n",
        "    int j = lowerBoundShared(R, n, a);\n",
        "    // В правом массиве R ищем позицию, где элементы становятся больше a\n",
        "    // Это бинарный поиск в shared memory\n",
        "\n",
        "    int i = k - j;\n",
        "    // Определяем, сколько элементов нужно взять из L, чтобы суммарно получилось k\n",
        "\n",
        "    if (i < 0) i = 0;\n",
        "    // Если получилось отрицательное значение, фиксируем его как 0\n",
        "\n",
        "    if (i > m) i = m;\n",
        "    // Если получилось больше размера L, ограничиваем максимумом m\n",
        "\n",
        "    float lv = (i < m) ? L[i] : 1e30f;\n",
        "    // Берём кандидата из левого массива (или большое число, если вышли за границы)\n",
        "\n",
        "    float rv = (j < n) ? R[j] : 1e30f;\n",
        "    // Берём кандидата из правого массива (или большое число, если вышли за границы)\n",
        "\n",
        "    out[base + k] = (lv <= rv) ? lv : rv;\n",
        "    // Записываем в итоговый массив меньший из двух кандидатов\n",
        "}\n",
        "// Конец цикла параллельного слияния\n",
        "}\n",
        "\n",
        "\n",
        "// Запуск редукции только через глобальную память\n",
        "float runReduceGlobal(const float* dIn, int N) {\n",
        "\n",
        "    float* dSum = nullptr;\n",
        "    // Указатель на переменную-сумму на GPU\n",
        "\n",
        "    CUDA_CHECK(cudaMalloc(&dSum, sizeof(float)));\n",
        "    // Выделяем память под одну переменную на GPU\n",
        "\n",
        "    CUDA_CHECK(cudaMemset(dSum, 0, sizeof(float)));\n",
        "    // Обнуляем сумму перед началом редукции\n",
        "\n",
        "    dim3 block(BLOCK);\n",
        "    // Задаём размер блока потоков\n",
        "\n",
        "    dim3 grid((N + BLOCK - 1) / BLOCK);\n",
        "    // Считаем количество блоков, чтобы покрыть весь массив\n",
        "\n",
        "    float ms = timeKernel([&] {\n",
        "        // Запускаем измерение времени выполнения kernel\n",
        "\n",
        "        reduce_global_only<<<grid, block>>>(dIn, dSum, N);\n",
        "        // Запускаем kernel редукции через глобальную память\n",
        "    });\n",
        "\n",
        "    CUDA_CHECK(cudaFree(dSum));\n",
        "    // Освобождаем память на GPU\n",
        "\n",
        "    return ms;\n",
        "    // Возвращаем измеренное время\n",
        "}\n",
        "\n",
        "// Запуск редукции с shared memory\n",
        "float runReduceShared(const float* dIn, int N) {\n",
        "\n",
        "    float* dSum = nullptr;\n",
        "    // Указатель на сумму на GPU\n",
        "\n",
        "    CUDA_CHECK(cudaMalloc(&dSum, sizeof(float)));\n",
        "    // Выделяем память под одну переменную\n",
        "\n",
        "    CUDA_CHECK(cudaMemset(dSum, 0, sizeof(float)));\n",
        "    // Обнуляем сумму перед запуском\n",
        "\n",
        "    dim3 block(BLOCK);\n",
        "    // Задаём размер блока потоков\n",
        "\n",
        "    dim3 grid((N + BLOCK - 1) / BLOCK);\n",
        "    // Считаем количество блоков\n",
        "\n",
        "    float ms = timeKernel([&] {\n",
        "        // Запускаем измерение времени\n",
        "\n",
        "        reduce_shared<<<grid, block>>>(dIn, dSum, N);\n",
        "        // Запускаем kernel редукции с использованием shared memory\n",
        "    });\n",
        "\n",
        "    CUDA_CHECK(cudaFree(dSum));\n",
        "    // Освобождаем память на GPU\n",
        "\n",
        "    return ms;\n",
        "    // Возвращаем измеренное время\n",
        "}\n",
        "\n",
        "// Запуск всей сортировочной pipeline:\n",
        "// 1. пузырёк по чанкам\n",
        "// 2. последовательные слияния\n",
        "float runSortPipeline(const vector<float>& h, int N) {\n",
        "\n",
        "    float *dA = nullptr, *dB = nullptr;\n",
        "    // Два массива на GPU: один для входа, второй как буфер\n",
        "\n",
        "    CUDA_CHECK(cudaMalloc(&dA, N * sizeof(float)));\n",
        "    // Выделяем память для первого массива\n",
        "\n",
        "    CUDA_CHECK(cudaMalloc(&dB, N * sizeof(float)));\n",
        "    // Выделяем память для буферного массива\n",
        "\n",
        "    CUDA_CHECK(cudaMemcpy(dA, h.data(), N * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    // Копируем данные с CPU на GPU\n",
        "\n",
        "    int numChunks = (N + CHUNK - 1) / CHUNK;\n",
        "    // Считаем, сколько блоков (чанков) нам нужно для пузырьковой сортировки\n",
        "\n",
        "    float ms = timeKernel([&] {\n",
        "        // Начинаем измерение времени всей сортировочной pipeline\n",
        "\n",
        "        bubble_chunks<<<numChunks, CHUNK>>>(dA, N);\n",
        "        // Запускаем kernel пузырьковой сортировки по чанкам\n",
        "\n",
        "        CUDA_CHECK(cudaDeviceSynchronize());\n",
        "        // Ждём завершения сортировки чанков\n",
        "\n",
        "        int width = CHUNK;\n",
        "        // Начальный размер сегмента для слияния\n",
        "\n",
        "        bool ping = true;\n",
        "        // Флаг для переключения между dA и dB\n",
        "\n",
        "        while (width < N) {\n",
        "            // Повторяем слияние, пока не соберём весь массив\n",
        "\n",
        "            size_t shmem = 2ULL * width * sizeof(float);\n",
        "            // Считаем, сколько shared memory нужно для двух сегментов\n",
        "\n",
        "            if (shmem > 48ULL * 1024ULL) break;\n",
        "            // Если shared памяти слишком много, прекращаем\n",
        "\n",
        "            int numPairs = (N + (2 * width) - 1) / (2 * width);\n",
        "            // Считаем, сколько пар сегментов будем сливать\n",
        "\n",
        "            const float* in  = ping ? dA : dB;\n",
        "            // Определяем входной массив\n",
        "\n",
        "            float* out       = ping ? dB : dA;\n",
        "            // Определяем выходной массив\n",
        "\n",
        "            merge_pass<<<numPairs, BLOCK, shmem>>>(in, out, N, width);\n",
        "            // Запускаем kernel слияния\n",
        "\n",
        "            CUDA_CHECK(cudaDeviceSynchronize());\n",
        "            // Ждём завершения слияния\n",
        "\n",
        "            ping = !ping;\n",
        "            // Меняем местами вход и выход\n",
        "\n",
        "            width *= 2;\n",
        "            // Увеличиваем размер сегмента вдвое\n",
        "        }\n",
        "    });\n",
        "\n",
        "    CUDA_CHECK(cudaFree(dA));\n",
        "    // Освобождаем первый массив\n",
        "\n",
        "    CUDA_CHECK(cudaFree(dB));\n",
        "    // Освобождаем буферный массив\n",
        "\n",
        "    return ms;\n",
        "    // Возвращаем общее время сортировки\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "    vector<int> sizes = {10000, 100000, 1000000};\n",
        "    // Три размера массивов по заданию\n",
        "\n",
        "    mt19937 gen(42);\n",
        "    // Генератор случайных чисел с фиксированным сидом\n",
        "\n",
        "    uniform_real_distribution<float> dist(0.0f, 100.0f);\n",
        "    // Диапазон случайных чисел\n",
        "\n",
        "    cout << \"\\nGPU Practical results\\n\";\n",
        "\n",
        "    cout << left\n",
        "         << setw(12) << \"N\"\n",
        "         << setw(22) << \"Reduce global (ms)\"\n",
        "         << setw(22) << \"Reduce shared (ms)\"\n",
        "         << setw(20) << \"Sort pipeline (ms)\"\n",
        "         << \"\\n\";\n",
        "    // Печатаем названия столбцов\n",
        "\n",
        "    cout << fixed << setprecision(6);\n",
        "    // Делаем вывод аккуратным с 6 знаками после запятой\n",
        "\n",
        "    for (int N : sizes) {\n",
        "        // Проходим по всем размерам массива\n",
        "\n",
        "        vector<float> h(N);\n",
        "        // Создаём массив на CPU\n",
        "\n",
        "        for (int i = 0; i < N; i++) h[i] = dist(gen);\n",
        "        // Заполняем его случайными числами\n",
        "\n",
        "        float* dIn = nullptr;\n",
        "        // Указатель на массив на GPU\n",
        "\n",
        "        CUDA_CHECK(cudaMalloc(&dIn, N * sizeof(float)));\n",
        "        // Выделяем память на GPU\n",
        "\n",
        "        CUDA_CHECK(cudaMemcpy(dIn, h.data(), N * sizeof(float), cudaMemcpyHostToDevice));\n",
        "        // Копируем данные на GPU\n",
        "\n",
        "        float tRedGlobal = runReduceGlobal(dIn, N);\n",
        "        // Замеряем время редукции через global memory\n",
        "\n",
        "        float tRedShared = runReduceShared(dIn, N);\n",
        "        // Замеряем время редукции через shared memory\n",
        "\n",
        "        float tSort = runSortPipeline(h, N);\n",
        "        // Замеряем время сортировочной pipeline\n",
        "\n",
        "        CUDA_CHECK(cudaFree(dIn));\n",
        "        // Освобождаем память на GPU\n",
        "\n",
        "        cout << left\n",
        "             << setw(12) << N\n",
        "             << setw(22) << tRedGlobal\n",
        "             << setw(22) << tRedShared\n",
        "             << setw(20) << tSort\n",
        "             << \"\\n\";\n",
        "        // Печатаем результаты в таблицу\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O3 -arch=sm_75 practice4.cu -o practice4\n",
        "!./practice4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iaMDpE_KAlF",
        "outputId": "ef8f6b48-57ec-41b1-91e5-1c58ba536fd5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPU Practical results\n",
            "N           Reduce global (ms)    Reduce shared (ms)    Sort pipeline (ms)  \n",
            "10000       0.167872              0.019872              1.878336            \n",
            "100000      0.356352              0.016768              5.248032            \n",
            "1000000     3.520160              0.106528              42.636097           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Вывод**\n",
        "\n",
        "В ходе работы были реализованы и протестированы три GPU-алгоритма: редукция суммы с использованием только глобальной памяти, редукция с применением разделяемой памяти, а также сортировочный конвейер, включающий локальную сортировку подмассивов и их последующее слияние. Эксперименты проводились для массивов размером 10 000, 100 000 и 1 000 000 элементов.\n",
        "\n",
        "Результаты показывают, что использование разделяемой памяти значительно ускоряет редукцию по сравнению с версией, основанной исключительно на глобальной памяти. Во всех случаях редукция с shared memory выполняется на порядок быстрее, что объясняется снижением количества медленных обращений к глобальной памяти и уменьшением нагрузки на атомарные операции.\n",
        "\n",
        "Сортировочный конвейер ожидаемо занимает больше времени, особенно при увеличении размера массива, так как включает несколько этапов обработки, в том числе локальную сортировку и многократные операции слияния. При размере массива 1 000 000 элементов время сортировки возрастает существенно, что подтверждает высокую вычислительную сложность данной процедуры.\n",
        "\n",
        "Таким образом, эксперимент демонстрирует, что грамотное использование разделяемой памяти может существенно повысить производительность CUDA-программ, особенно для задач редукции, тогда как сложные сортировочные алгоритмы требуют дополнительных оптимизаций для эффективного масштабирования на больших данных."
      ],
      "metadata": {
        "id": "_Ugu2qXanF1a"
      }
    }
  ]
}