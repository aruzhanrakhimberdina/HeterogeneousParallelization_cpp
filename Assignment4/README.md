# Контрольные вопросы

## 1. В чём заключается отличие гибридных вычислений от вычислений только на CPU или только на GPU?

Гибридные вычисления предполагают одновременное использование CPU и GPU для решения одной задачи. В отличие от вычислений только на CPU или только на GPU, в гибридном подходе работа распределяется между устройствами с учётом их сильных сторон. CPU обычно выполняет последовательные и управляющие операции, а GPU используется для вычислительно интенсивных и хорошо параллелизуемых частей. Такой подход позволяет более эффективно использовать вычислительные ресурсы системы и уменьшить общее время выполнения программы.

---

## 2. Для каких типов задач целесообразно распределять вычисления между CPU и GPU?

Распределять вычисления между CPU и GPU целесообразно для задач, которые можно разделить на независимые части и выполнять параллельно. К таким задачам относятся обработка больших массивов данных, численные методы, линейная алгебра, машинное обучение, обработка изображений и сигналов. Особенно эффективно использовать гибридный подход, когда часть задачи плохо параллелизуется и выполняется на CPU, а другая часть хорошо масштабируется на GPU.

---

## 3. В чём разница между синхронной и асинхронной передачей данных между CPU и GPU?

При синхронной передаче данных выполнение программы приостанавливается до завершения копирования данных между CPU и GPU. При асинхронной передаче данные копируются в фоновом режиме, а CPU или GPU могут продолжать выполнение других операций. Асинхронная передача позволяет перекрывать вычисления и обмен данными, что повышает общую эффективность программы.

---

## 4. Почему асинхронная передача данных может повысить производительность программы?

Асинхронная передача данных уменьшает время простоя вычислительных устройств. Пока данные передаются между CPU и GPU, одно из устройств может выполнять вычисления. За счёт такого перекрытия операций общее время выполнения программы сокращается, что приводит к росту производительности.

---

## 5. Какие основные функции MPI используются для распределения и сбора данных между процессами?

Для распределения данных между процессами в MPI часто используется функция `MPI_Scatter`, которая передаёт части массива от одного процесса ко всем остальным. Для объединения результатов применяется функция `MPI_Reduce`, позволяющая выполнить операцию над локальными результатами, например суммирование. Также используется функция `MPI_Gather`, которая собирает данные от всех процессов без выполнения вычислений над ними.

---

## 6. Как количество процессов MPI влияет на время выполнения программы и почему?

Увеличение количества процессов MPI может уменьшить время выполнения программы за счёт параллельной обработки данных. Однако при большом числе процессов увеличиваются накладные расходы на обмен данными и синхронизацию. В результате выигрыш от параллелизма может уменьшиться, и время выполнения программы перестаёт снижаться или даже увеличивается.

---

## 7. Какие факторы ограничивают масштабируемость распределённых параллельных программ?

Масштабируемость распределённых программ ограничивается затратами на коммуникацию между процессами, задержками передачи данных, необходимостью синхронизации, неравномерным распределением нагрузки и наличием последовательных участков кода. Все эти факторы уменьшают эффективность увеличения числа процессов.

---

## 8. В каких случаях использование распределённых вычислений оправдано, а в каких — неэффективно?

Распределённые вычисления оправданы для задач с большим объёмом данных и высокой вычислительной сложностью, которые можно эффективно разделить между процессами. К таким задачам относятся научные расчёты, моделирование и анализ больших данных. Использование распределённых вычислений неэффективно для небольших задач или задач с частыми обменами данными, где накладные расходы на коммуникацию превышают выигрыш от параллелизма.
