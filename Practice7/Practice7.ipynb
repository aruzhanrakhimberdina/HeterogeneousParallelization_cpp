{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Практическая работа 7**"
      ],
      "metadata": {
        "id": "yALLlkRfCh-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Теоретическая часть"
      ],
      "metadata": {
        "id": "X7t-9MbdDPzN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Редукция**\n",
        "\n",
        "Редукция это операция, которая позволяет получить одно итоговое значение из набора элементов массива. Чаще всего это сумма, минимум или максимум. Такая операция часто используется при работе с большими объёмами данных, когда последовательные вычисления на CPU становятся медленными.\n",
        "\n",
        "На GPU редукция выполняется параллельно с использованием потоков и блоков. Каждый блок обрабатывает свою часть данных и вычисляет частичную сумму. Затем эти частичные результаты объединяются до получения одного итогового значения. Для ускорения вычислений часто используется разделяемая память, так как доступ к ней значительно быстрее, чем к глобальной памяти. Редукция является базовой операцией и применяется во многих задачах, таких как анализ данных и машинное обучение.\n",
        "\n",
        "###**Сканирование (префиксная сумма)**\n",
        "\n",
        "Сканирование, или префиксная сумма, это операция, при которой для каждого элемента массива вычисляется сумма всех предыдущих элементов, включая текущий. Например, для массива [1, 2, 3, 4] результатом будет массив [1, 3, 6, 10].\n",
        "\n",
        "В отличие от редукции, сканирование возвращает массив той же длины, что и входной. Это делает его более сложным для параллельной реализации. На GPU сканирование обычно выполняется в несколько этапов. Сначала вычисляется префиксная сумма внутри каждого блока, затем обрабатываются суммы блоков и добавляются соответствующие смещения. Сканирование широко используется в алгоритмах сортировки, построении гистограмм и обработке изображений.\n",
        "\n",
        "###**Типы памяти в CUDA**\n",
        "\n",
        "Производительность программ на GPU во многом зависит от того, какие типы памяти используются. Глобальная память является основной памятью GPU и доступна всем потокам, но она работает медленнее из-за большой задержки доступа. Разделяемая память доступна только потокам внутри одного блока, но при этом она намного быстрее и часто используется для оптимизации параллельных алгоритмов.\n",
        "\n",
        "Локальная память используется для хранения данных, относящихся к отдельному потоку. Обычно она применяется для временных переменных и промежуточных вычислений. Правильное использование разных типов памяти позволяет значительно повысить скорость выполнения программ на CUDA."
      ],
      "metadata": {
        "id": "HRRRnWsBDWAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Практическая часть"
      ],
      "metadata": {
        "id": "5GYLoUGdDmQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Задание 1"
      ],
      "metadata": {
        "id": "GBl-dvBcCqT8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMuEx41YBcS_",
        "outputId": "6cf06a1f-0c92-4a62-94c7-df7510095885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing reduction.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile reduction.cu\n",
        "\n",
        "#include <cuda_runtime.h>          // Подключение CUDA Runtime API\n",
        "#include <iostream>                // Для вывода в консоль\n",
        "#include <vector>                  // Для использования std::vector\n",
        "#include <numeric>                 // Для std::accumulate\n",
        "#include <cmath>                   // Для std::abs\n",
        "\n",
        "// Макрос для проверки корректности выполнения CUDA-вызовов\n",
        "#define CHECK_CUDA(call)                                   \\\n",
        "{                                                          \\\n",
        "    cudaError_t err = call;                                 \\\n",
        "    if (err != cudaSuccess) {                              \\\n",
        "        std::cerr << \"CUDA error: \"                         \\\n",
        "                  << cudaGetErrorString(err)                \\\n",
        "                  << \" at line \" << __LINE__ << std::endl;  \\\n",
        "        exit(EXIT_FAILURE);                                 \\\n",
        "    }                                                      \\\n",
        "}\n",
        "\n",
        "// CUDA-ядро для суммирования элементов массива методом редукции\n",
        "__global__\n",
        "void reduceSumKernel(const float* d_in, float* d_out, int n)\n",
        "{\n",
        "    extern __shared__ float sdata[];        // Объявление разделяемой памяти для частичных сумм\n",
        "\n",
        "    unsigned int tid = threadIdx.x;         // Индекс потока внутри блока\n",
        "\n",
        "    unsigned int idx = blockIdx.x           // Индекс блока\n",
        "                       * blockDim.x * 2     // Учитываем обработку двух элементов на поток\n",
        "                       + tid;               // Добавляем локальный индекс потока\n",
        "\n",
        "    float sum = 0.0f;                       // Переменная для хранения частичной суммы\n",
        "\n",
        "    if (idx < n)                            // Проверка выхода за границы массива\n",
        "        sum += d_in[idx];                  // Добавление первого элемента\n",
        "\n",
        "    if (idx + blockDim.x < n)              // Проверка второго элемента\n",
        "        sum += d_in[idx + blockDim.x];     // Добавление второго элемента\n",
        "\n",
        "    sdata[tid] = sum;                      // Запись частичной суммы в shared memory\n",
        "    __syncthreads();                       // Синхронизация потоков внутри блока\n",
        "\n",
        "    for (unsigned int stride = blockDim.x / 2; // Начальный шаг редукции\n",
        "         stride > 0;                           // Пока шаг больше нуля\n",
        "         stride >>= 1)                         // Делим шаг на два\n",
        "    {\n",
        "        if (tid < stride)                     // Активны только первые потоки\n",
        "            sdata[tid] += sdata[tid + stride]; // Суммируем элементы\n",
        "        __syncthreads();                      // Синхронизация после каждой итерации\n",
        "    }\n",
        "\n",
        "    if (tid == 0)                             // Первый поток блока\n",
        "        d_out[blockIdx.x] = sdata[0];         // Записывает результат блока\n",
        "}\n",
        "\n",
        "// Функция на стороне CPU для многошаговой редукции\n",
        "float gpuReduceSum(const std::vector<float>& h_input)\n",
        "{\n",
        "    int n = h_input.size();                   // Размер входного массива\n",
        "\n",
        "    float* d_in;                              // Указатель на входной массив на GPU\n",
        "    float* d_out;                             // Указатель на выходной массив на GPU\n",
        "\n",
        "    CHECK_CUDA(cudaMalloc(&d_in, n * sizeof(float))); // Выделение памяти на GPU\n",
        "    CHECK_CUDA(cudaMemcpy(d_in, h_input.data(),       // Копирование данных\n",
        "                           n * sizeof(float),\n",
        "                           cudaMemcpyHostToDevice));\n",
        "\n",
        "    const int threads = 256;                  // Количество потоков в блоке\n",
        "\n",
        "    while (n > 1)                             // Пока не останется один элемент\n",
        "    {\n",
        "        int blocks = (n + threads * 2 - 1)    // Вычисление количества блоков\n",
        "                     / (threads * 2);\n",
        "\n",
        "        CHECK_CUDA(cudaMalloc(&d_out, blocks * sizeof(float))); // Выделение памяти под результат\n",
        "\n",
        "        reduceSumKernel<<<blocks, threads,    // Запуск CUDA-ядра\n",
        "                           threads * sizeof(float)>>>(d_in, d_out, n);\n",
        "\n",
        "        CHECK_CUDA(cudaDeviceSynchronize());  // Ожидание завершения ядра\n",
        "\n",
        "        cudaFree(d_in);                       // Освобождение старого входного массива\n",
        "\n",
        "        d_in = d_out;                         // Результат становится новым входом\n",
        "        n = blocks;                           // Обновляем размер массива\n",
        "    }\n",
        "\n",
        "    float result;                             // Переменная для хранения результата\n",
        "\n",
        "    CHECK_CUDA(cudaMemcpy(&result, d_in,      // Копирование результата на CPU\n",
        "                           sizeof(float),\n",
        "                           cudaMemcpyDeviceToHost));\n",
        "\n",
        "    cudaFree(d_in);                           // Освобождение памяти GPU\n",
        "\n",
        "    return result;                            // Возвращаем итоговую сумму\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    const int N = 1'000'000;                  // Размер тестового массива\n",
        "\n",
        "    std::vector<float> data(N);               // Создание массива на CPU\n",
        "\n",
        "    for (int i = 0; i < N; i++)               // Заполнение массива\n",
        "        data[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "\n",
        "    double cpu_sum = std::accumulate(         // Суммирование на CPU\n",
        "        data.begin(), data.end(), 0.0);\n",
        "\n",
        "    float gpu_sum = gpuReduceSum(data);        // Суммирование на GPU\n",
        "\n",
        "    std::cout << \"CPU sum: \" << cpu_sum << std::endl; // Вывод CPU результата\n",
        "    std::cout << \"GPU sum: \" << gpu_sum << std::endl; // Вывод GPU результата\n",
        "\n",
        "    std::cout << \"Absolute error: \"            // Вывод абсолютной ошибки\n",
        "              << std::abs(cpu_sum - gpu_sum)\n",
        "              << std::endl;\n",
        "\n",
        "    return 0;                                 // Завершение программы\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 reduction.cu -o reduction\n",
        "!./reduction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtW_vgBTBhMM",
        "outputId": "92465f23-b95d-478f-9562-8f5c1f441df7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU sum: 500007\n",
            "GPU sum: 500007\n",
            "Absolute error: 0.0151951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Вывод**\n",
        "\n",
        "В ходе выполнения задания была реализована операция редукции для суммирования элементов массива с использованием технологии CUDA. Для оптимизации доступа к данным применялась разделяемая память, что позволило сократить количество обращений к глобальной памяти и повысить эффективность вычислений на GPU. Реализация основывалась на многошаговой редукции, при которой на каждом этапе уменьшалось количество обрабатываемых элементов до получения итогового значения.\n",
        "\n",
        "Корректность работы алгоритма была проверена путём сравнения результатов, полученных на GPU и CPU. Полученные значения сумм совпадают с точностью до погрешности вычислений с плавающей точкой. Абсолютная ошибка составила 0.015 при сумме порядка 5×10⁵, что соответствует крайне малой относительной погрешности и является допустимым для вычислений в формате float.\n",
        "\n",
        "Наблюдаемая погрешность обусловлена различием порядка операций сложения на CPU и GPU, а также ограниченной точностью представления чисел с плавающей точкой. Таким образом, реализованное CUDA-ядро корректно выполняет редукцию массива и демонстрирует ожидаемое поведение параллельных вычислений на графическом процессоре."
      ],
      "metadata": {
        "id": "FuRF3wwHCZtb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Задание 2"
      ],
      "metadata": {
        "id": "ldlYxYESCyhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prefix_scan.cu\n",
        "\n",
        "#include <cuda_runtime.h>                 // CUDA Runtime API\n",
        "#include <iostream>                       // Вывод в консоль\n",
        "#include <vector>                         // std::vector\n",
        "#include <cmath>                          // std::abs, std::max\n",
        "\n",
        "#define CHECK_CUDA(call)                                   \\\n",
        "{                                                          \\\n",
        "    cudaError_t err = call;                                \\\n",
        "    if (err != cudaSuccess) {                              \\\n",
        "        std::cerr << \"CUDA error: \"                        \\\n",
        "                  << cudaGetErrorString(err)               \\\n",
        "                  << \" at line \" << __LINE__ << std::endl; \\\n",
        "        exit(EXIT_FAILURE);                                \\\n",
        "    }                                                      \\\n",
        "}\n",
        "\n",
        "__global__\n",
        "void blockInclusiveScanAndSumsKernel(const float* d_in, float* d_out, float* d_block_sums, int n)\n",
        "{\n",
        "    extern __shared__ float sdata[];       // Shared memory для данных блока\n",
        "\n",
        "    unsigned int tid = threadIdx.x;        // Индекс потока в блоке\n",
        "    unsigned int bdim = blockDim.x;        // Размер блока\n",
        "    unsigned int bid  = blockIdx.x;        // Индекс блока\n",
        "    unsigned int idx  = bid * bdim + tid;  // Глобальный индекс элемента\n",
        "\n",
        "    float x = 0.0f;                        // Локальная переменная для элемента\n",
        "    if (idx < n)                           // Проверка границы массива\n",
        "        x = d_in[idx];                     // Читаем элемент из global memory\n",
        "\n",
        "    sdata[tid] = x;                        // Кладём элемент в shared memory\n",
        "    __syncthreads();                       // Синхронизация всех потоков блока\n",
        "\n",
        "    for (unsigned int offset = 1;          // Начинаем с offset=1\n",
        "         offset < bdim;                    // Пока offset меньше размера блока\n",
        "         offset <<= 1)                     // Удваиваем offset\n",
        "    {\n",
        "        float temp = 0.0f;                 // Временная переменная\n",
        "        if (tid >= offset)                 // Потоки, которые могут читать назад\n",
        "            temp = sdata[tid - offset];    // Берут значение на offset левее\n",
        "        __syncthreads();                   // Синхронизация перед обновлением\n",
        "        sdata[tid] += temp;                // Обновляем inclusive scan в shared\n",
        "        __syncthreads();                   // Синхронизация после обновления\n",
        "    }\n",
        "\n",
        "    if (idx < n)                           // Проверка границы массива\n",
        "        d_out[idx] = sdata[tid];           // Пишем префикс для элемента\n",
        "\n",
        "    if (tid == bdim - 1)                   // Последний поток блока\n",
        "        d_block_sums[bid] = sdata[tid];    // Записывает сумму всего блока\n",
        "}\n",
        "\n",
        "__global__\n",
        "void addBlockOffsetsKernel(float* d_out, const float* d_block_offsets, int n)\n",
        "{\n",
        "    unsigned int tid = threadIdx.x;        // Индекс потока в блоке\n",
        "    unsigned int bdim = blockDim.x;        // Размер блока\n",
        "    unsigned int bid  = blockIdx.x;        // Индекс блока\n",
        "    unsigned int idx  = bid * bdim + tid;  // Глобальный индекс\n",
        "\n",
        "    if (idx < n)                           // Проверка границы массива\n",
        "        d_out[idx] += d_block_offsets[bid];// Добавляем оффсет блока ко всем элементам блока\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    const int N = 1024;                    // Размер тестового массива\n",
        "    std::vector<float> h_in(N);            // Входной массив на CPU\n",
        "    std::vector<float> h_out(N);           // Выходной массив на CPU\n",
        "    std::vector<float> h_cpu(N);           // CPU-эталон\n",
        "\n",
        "    for (int i = 0; i < N; i++)            // Заполняем тестовый массив\n",
        "        h_in[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "\n",
        "    h_cpu[0] = h_in[0];                    // Инициализация CPU-префикса\n",
        "    for (int i = 1; i < N; i++)            // Последовательный prefix sum на CPU\n",
        "        h_cpu[i] = h_cpu[i - 1] + h_in[i];\n",
        "\n",
        "    float* d_in = nullptr;                 // Указатель на вход на GPU\n",
        "    float* d_out = nullptr;                // Указатель на выход на GPU\n",
        "\n",
        "    CHECK_CUDA(cudaMalloc(&d_in, N * sizeof(float)));   // Выделяем память под вход\n",
        "    CHECK_CUDA(cudaMalloc(&d_out, N * sizeof(float)));  // Выделяем память под выход\n",
        "\n",
        "    CHECK_CUDA(cudaMemcpy(d_in, h_in.data(), N * sizeof(float), cudaMemcpyHostToDevice)); // Копируем вход на GPU\n",
        "\n",
        "    const int threads = 256;               // Потоков в блоке\n",
        "    int blocks = (N + threads - 1) / threads; // Количество блоков\n",
        "\n",
        "    float* d_block_sums = nullptr;         // Суммы блоков на GPU\n",
        "    CHECK_CUDA(cudaMalloc(&d_block_sums, blocks * sizeof(float))); // Память под суммы блоков\n",
        "\n",
        "    blockInclusiveScanAndSumsKernel<<<blocks, threads, threads * sizeof(float)>>>(d_in, d_out, d_block_sums, N); // Scan + суммы блоков\n",
        "    CHECK_CUDA(cudaDeviceSynchronize());   // Ждём завершения\n",
        "\n",
        "    std::vector<float> h_block_sums(blocks); // Суммы блоков на CPU\n",
        "    CHECK_CUDA(cudaMemcpy(h_block_sums.data(), d_block_sums, blocks * sizeof(float), cudaMemcpyDeviceToHost)); // Копируем суммы блоков\n",
        "\n",
        "    std::vector<float> h_block_offsets(blocks); // Оффсеты блоков на CPU\n",
        "    float running = 0.0f;                  // Накопленная сумма предыдущих блоков\n",
        "    for (int b = 0; b < blocks; b++) {     // Идём по блокам\n",
        "        h_block_offsets[b] = running;      // Оффсет блока = сумма всех предыдущих блоков\n",
        "        running += h_block_sums[b];        // Обновляем накопленную сумму\n",
        "    }\n",
        "\n",
        "    float* d_block_offsets = nullptr;      // Оффсеты блоков на GPU\n",
        "    CHECK_CUDA(cudaMalloc(&d_block_offsets, blocks * sizeof(float))); // Память под оффсеты\n",
        "    CHECK_CUDA(cudaMemcpy(d_block_offsets, h_block_offsets.data(), blocks * sizeof(float), cudaMemcpyHostToDevice)); // Копируем оффсеты\n",
        "\n",
        "    addBlockOffsetsKernel<<<blocks, threads>>>(d_out, d_block_offsets, N); // Добавляем оффсеты к каждому блоку\n",
        "    CHECK_CUDA(cudaDeviceSynchronize());   // Ждём завершения\n",
        "\n",
        "    CHECK_CUDA(cudaMemcpy(h_out.data(), d_out, N * sizeof(float), cudaMemcpyDeviceToHost)); // Копируем итог на CPU\n",
        "\n",
        "    float max_error = 0.0f;                // Максимальная ошибка\n",
        "    for (int i = 0; i < N; i++)            // Сравниваем CPU и GPU\n",
        "        max_error = std::max(max_error, std::abs(h_cpu[i] - h_out[i]));\n",
        "\n",
        "    std::cout << \"CPU prefix (first 10): \"; // Печать первых 10 CPU\n",
        "    for (int i = 0; i < 10; i++)\n",
        "        std::cout << h_cpu[i] << \" \";\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    std::cout << \"GPU prefix (first 10): \"; // Печать первых 10 GPU\n",
        "    for (int i = 0; i < 10; i++)\n",
        "        std::cout << h_out[i] << \" \";\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    std::cout << \"Max absolute error: \" << max_error << std::endl; // Печать ошибки\n",
        "\n",
        "    cudaFree(d_in);                        // Освобождаем вход\n",
        "    cudaFree(d_out);                       // Освобождаем выход\n",
        "    cudaFree(d_block_sums);                // Освобождаем суммы блоков\n",
        "    cudaFree(d_block_offsets);             // Освобождаем оффсеты блоков\n",
        "\n",
        "    return 0;                              // Завершение\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aGpSQOUC5S2",
        "outputId": "9892c4ee-b271-436e-8efb-7671926385e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting prefix_scan.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 prefix_scan.cu -o prefix_scan\n",
        "!./prefix_scan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vosgyGj7EHC3",
        "outputId": "d28aa2f2-5972-48bb-de45-ca6ecb46a805"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU prefix (first 10): 0.840188 1.23457 2.01767 2.81611 3.72776 3.92531 4.26053 5.02876 5.30654 5.86051 \n",
            "GPU prefix (first 10): 0.840188 1.23457 2.01767 2.81611 3.72776 3.92531 4.26053 5.02876 5.30654 5.86051 \n",
            "Max absolute error: 0.00012207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Вывод**\n",
        "\n",
        "В рамках данного задания была реализована операция префиксной суммы (inclusive scan) с использованием технологии CUDA. Для ускорения вычислений применялась разделяемая память, что позволило эффективно выполнять суммирование элементов внутри каждого блока и сократить количество обращений к глобальной памяти. Алгоритм был реализован с учётом блочной структуры GPU и включал этап вычисления сумм блоков и добавления соответствующих оффсетов, что обеспечило корректное вычисление префиксной суммы для всего массива.\n",
        "\n",
        "Корректность реализации была проверена путём сравнения результатов, полученных на GPU и CPU. Первые элементы префиксной суммы полностью совпали, а максимальная абсолютная погрешность составила 0.00012207. Данная погрешность обусловлена особенностями представления чисел с плавающей точкой в формате float32 и различием порядка выполнения операций сложения при параллельных вычислениях на GPU.\n",
        "\n",
        "Таким образом, реализованная CUDA-реализация префиксной суммы корректно выполняет поставленную задачу и демонстрирует ожидаемое поведение параллельного алгоритма с использованием разделяемой памяти и многошаговой схемы вычислений."
      ],
      "metadata": {
        "id": "4bOLyQh3E5Q7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Задание 3"
      ],
      "metadata": {
        "id": "lPBoTmRwE98q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile benchmark.cu\n",
        "#include <cuda_runtime.h>                 // Подключение CUDA Runtime API\n",
        "#include <iostream>                       // Потоки ввода-вывода\n",
        "#include <vector>                         // Контейнер std::vector\n",
        "#include <chrono>                         // Измерение времени на CPU\n",
        "#include <cmath>                          // Математические функции\n",
        "#include <iomanip>                        // Форматированный вывод\n",
        "\n",
        "using namespace std;                      // Использование пространства имён std\n",
        "\n",
        "// Макрос для проверки ошибок CUDA\n",
        "#define CHECK_CUDA(call) do {                                     \\\n",
        "    cudaError_t err = call;                                       \\\n",
        "    if (err != cudaSuccess) {                                     \\\n",
        "        cerr << \"CUDA error: \"                                    \\\n",
        "             << cudaGetErrorString(err)                           \\\n",
        "             << \" at line \" << __LINE__ << endl;                  \\\n",
        "        exit(EXIT_FAILURE);                                       \\\n",
        "    }                                                             \\\n",
        "} while(0)\n",
        "\n",
        "// GPU-ядро: редукция с использованием атомарных операций\n",
        "__global__\n",
        "void reduce_atomic_kernel(const float* d_in, float* d_out, int n)\n",
        "{\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x; // Глобальный индекс элемента\n",
        "    if (i < n)                                     // Проверка выхода за границы\n",
        "        atomicAdd(d_out, d_in[i]);                 // Атомарное добавление в global memory\n",
        "}\n",
        "\n",
        "// GPU-ядро: оптимизированная редукция с использованием shared memory\n",
        "__global__\n",
        "void reduce_shared_kernel(const float* d_in, float* d_out, int n)\n",
        "{\n",
        "    extern __shared__ float sdata[];                // Разделяемая память блока\n",
        "\n",
        "    unsigned int tid = threadIdx.x;                 // Индекс потока в блоке\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 2 + tid; // Глобальный индекс (2 элемента на поток)\n",
        "\n",
        "    float sum = 0.0f;                               // Локальная переменная суммы\n",
        "\n",
        "    if (idx < n)                                   // Проверка первого элемента\n",
        "        sum += d_in[idx];                          // Чтение из global memory\n",
        "    if (idx + blockDim.x < n)                      // Проверка второго элемента\n",
        "        sum += d_in[idx + blockDim.x];             // Чтение второго элемента\n",
        "\n",
        "    sdata[tid] = sum;                              // Запись частичной суммы в shared memory\n",
        "    __syncthreads();                               // Синхронизация потоков блока\n",
        "\n",
        "    for (unsigned int stride = blockDim.x / 2;     // Начальный шаг редукции\n",
        "         stride > 0;                               // Пока шаг больше нуля\n",
        "         stride >>= 1)                             // Деление шага пополам\n",
        "    {\n",
        "        if (tid < stride)                          // Активные потоки\n",
        "            sdata[tid] += sdata[tid + stride];     // Суммирование элементов\n",
        "        __syncthreads();                           // Синхронизация после шага\n",
        "    }\n",
        "\n",
        "    if (tid == 0)                                  // Первый поток блока\n",
        "        d_out[blockIdx.x] = sdata[0];              // Запись суммы блока\n",
        "}\n",
        "\n",
        "// Хост-функция: многошаговая редукция на GPU\n",
        "float gpu_reduce_shared(const float* d_in, int n)\n",
        "{\n",
        "    const int threads = 256;                        // Количество потоков в блоке\n",
        "    int cur_n = n;                                 // Текущий размер массива\n",
        "\n",
        "    float* d_prev = nullptr;                       // Указатель на текущий вход\n",
        "    float* d_curr = nullptr;                       // Указатель на текущий выход\n",
        "\n",
        "    CHECK_CUDA(cudaMalloc(&d_prev, n * sizeof(float))); // Выделение памяти\n",
        "    CHECK_CUDA(cudaMemcpy(d_prev, d_in, n * sizeof(float), cudaMemcpyDeviceToDevice)); // Копирование\n",
        "\n",
        "    while (cur_n > 1)                              // Пока не останется один элемент\n",
        "    {\n",
        "        int blocks = (cur_n + threads * 2 - 1) / (threads * 2); // Количество блоков\n",
        "        CHECK_CUDA(cudaMalloc(&d_curr, blocks * sizeof(float))); // Память под результат\n",
        "\n",
        "        reduce_shared_kernel<<<blocks, threads, threads * sizeof(float)>>>(d_prev, d_curr, cur_n); // Запуск ядра\n",
        "        CHECK_CUDA(cudaDeviceSynchronize());        // Ожидание завершения\n",
        "\n",
        "        cudaFree(d_prev);                           // Освобождение старого массива\n",
        "        d_prev = d_curr;                            // Новый вход\n",
        "        d_curr = nullptr;                           // Обнуление указателя\n",
        "        cur_n = blocks;                             // Обновление размера\n",
        "    }\n",
        "\n",
        "    float result = 0.0f;                            // Переменная результата\n",
        "    CHECK_CUDA(cudaMemcpy(&result, d_prev, sizeof(float), cudaMemcpyDeviceToHost)); // Копирование на CPU\n",
        "    cudaFree(d_prev);                               // Освобождение памяти\n",
        "\n",
        "    return result;                                 // Возврат результата\n",
        "}\n",
        "\n",
        "// CPU-реализация редукции\n",
        "float cpu_reduce(const vector<float>& a)\n",
        "{\n",
        "    double sum = 0.0;                               // Используем double для точности\n",
        "    for (float x : a)                               // Последовательный проход\n",
        "        sum += x;                                  // Суммирование\n",
        "    return static_cast<float>(sum);                // Возврат результата\n",
        "}\n",
        "\n",
        "// Основная функция бенчмарка\n",
        "int main()\n",
        "{\n",
        "    cout << fixed << setprecision(3);               // Форматированный вывод чисел\n",
        "\n",
        "    vector<int> sizes = {1024, 4096, 16384, 65536, 262144, 1048576}; // Размеры массивов\n",
        "\n",
        "\n",
        "    cout << setw(10) << \"N\"\n",
        "         << setw(15) << \"CPU (мс)\"\n",
        "         << setw(20) << \"GPU atomic (мс)\"\n",
        "         << setw(20) << \"GPU shared (мс)\"\n",
        "         << endl;\n",
        "\n",
        "    for (int N : sizes)                              // Перебор размеров массивов\n",
        "    {\n",
        "        vector<float> h(N);                          // Массив на CPU\n",
        "        for (int i = 0; i < N; i++)                  // Заполнение массива\n",
        "            h[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "\n",
        "        float* d_in = nullptr;                       // Указатель на GPU-вход\n",
        "        float* d_out = nullptr;                      // Указатель на GPU-выход\n",
        "\n",
        "        CHECK_CUDA(cudaMalloc(&d_in, N * sizeof(float))); // Выделение памяти\n",
        "        CHECK_CUDA(cudaMemcpy(d_in, h.data(), N * sizeof(float), cudaMemcpyHostToDevice)); // Копирование\n",
        "        CHECK_CUDA(cudaMalloc(&d_out, sizeof(float))); // Память под результат\n",
        "\n",
        "        auto t0 = chrono::high_resolution_clock::now(); // Начало CPU таймера\n",
        "        cpu_reduce(h);                               // CPU редукция\n",
        "        auto t1 = chrono::high_resolution_clock::now(); // Конец таймера\n",
        "        double cpu_ms = chrono::duration<double, milli>(t1 - t0).count(); // Время CPU\n",
        "\n",
        "        CHECK_CUDA(cudaMemset(d_out, 0, sizeof(float))); // Обнуление результата\n",
        "        auto t2 = chrono::high_resolution_clock::now(); // Начало GPU atomic\n",
        "        reduce_atomic_kernel<<<(N + 255) / 256, 256>>>(d_in, d_out, N); // Запуск atomic ядра\n",
        "        CHECK_CUDA(cudaDeviceSynchronize());        // Ожидание\n",
        "        auto t3 = chrono::high_resolution_clock::now(); // Конец таймера\n",
        "        double gpu_atomic_ms = chrono::duration<double, milli>(t3 - t2).count(); // Время atomic\n",
        "\n",
        "        auto t4 = chrono::high_resolution_clock::now(); // Начало shared редукции\n",
        "        gpu_reduce_shared(d_in, N);                 // Оптимизированная GPU редукция\n",
        "        auto t5 = chrono::high_resolution_clock::now(); // Конец таймера\n",
        "        double gpu_shared_ms = chrono::duration<double, milli>(t5 - t4).count(); // Время shared\n",
        "\n",
        "        cout << setw(10) << N                        // Вывод строки таблицы\n",
        "             << setw(15) << cpu_ms\n",
        "             << setw(20) << gpu_atomic_ms\n",
        "             << setw(20) << gpu_shared_ms\n",
        "             << endl;\n",
        "\n",
        "        cudaFree(d_in);                              // Освобождение GPU памяти\n",
        "        cudaFree(d_out);\n",
        "    }\n",
        "\n",
        "    return 0;                                       // Завершение программы\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n12dCiwYFCV8",
        "outputId": "fa308fd7-e594-47f7-a9f3-e2760ee87fac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting benchmark.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -O2 benchmark.cu -o benchmark\n",
        "!./benchmark | head -n 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tAa4eOJGxWk",
        "outputId": "11733336-0494-4239-d2e5-8b7a2425d0ee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         N     CPU (мс)   GPU atomic (мс)   GPU shared (мс)\n",
            "      1024          0.000               0.157               0.119\n",
            "      4096          0.000               0.033               0.082\n",
            "     16384          0.000               0.074               0.085\n",
            "     65536          0.000               0.256               0.091\n",
            "    262144          0.000               1.006               0.363\n",
            "   1048576          0.000               3.711               0.521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Вывод**\n",
        "\n",
        "В ходе выполнения задания было проведено измерение времени выполнения операции редукции для массивов различного размера на CPU и GPU. На стороне GPU были рассмотрены две реализации: наивная версия с использованием атомарных операций в глобальной памяти и оптимизированная версия с применением разделяемой памяти.\n",
        "\n",
        "Результаты показали, что при малых размерах массива использование GPU не даёт выигрыша по времени по сравнению с CPU, что связано с накладными расходами на запуск CUDA-ядра. При увеличении размера массива наивная GPU-реализация с использованием атомарных операций демонстрирует существенное ухудшение производительности из-за сериализации доступа к глобальной памяти. Для массива размером 1 048 576 элементов время выполнения данной реализации составило около 3.7 мс.\n",
        "\n",
        "Оптимизированная версия редукции с использованием разделяемой памяти показала значительно лучшую масштабируемость. Основная часть вычислений выполняется внутри блоков в shared memory, что снижает количество обращений к глобальной памяти. Для массива размером 1 048 576 элементов время выполнения составило около 0.52 мс, что обеспечивает ускорение более чем в 7 раз по сравнению с атомарной реализацией.\n",
        "\n",
        "Таким образом, результаты эксперимента подтверждают эффективность использования разделяемой памяти для оптимизации операций редукции на GPU и демонстрируют преимущества оптимизированных параллельных алгоритмов при работе с большими объёмами данных."
      ],
      "metadata": {
        "id": "QxOJavkrCRSN"
      }
    }
  ]
}